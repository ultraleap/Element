#include <stdio.h>
#include <stdlib.h>
#include <stddef.h>
#include <stdint.h>
#include <stdbool.h>
#include <math.h>
#include <limits.h>
#include <assert.h>
#include "lmnt/common.h"
#include "lmnt/interpreter.h"
#include "lmnt/jit.h"
#include "helpers.h"
#include "jit/hosthelpers.h"
#include "jit/targethelpers-arm.h" // includes dasm_proto
#include "jit/reghelpers-arm-vfp.h"
#include "jit/op_impls.h"
#include LMNT_MEMORY_HEADER

| .arch armv7m
| .section rodata, code
| .globals lbl_
| .actionlist lmnt_actions

| .define rArg1, r0
| .define rArg2, r1
| .define rArg3, r2
| .define rArg4, r3
| .define rtmp1, r2
| .define rtmp2, r3

| .define rContext, r10
| .define rStack, r11
// TODO: scalar vs vector?
| .define vtmps1, 4
| .define vtmps2, 5
| .define vtmps3, 6
| .define vtmps4, 7
| .define vtmps5, 0
| .define vtmps6, 1
| .define vtmps7, 2
| .define vtmps8, 3
| .define vtmpv1, 4
| .define vtmpv2, 0


// If we use any of these non-volatile registers within *our* function
// (NOT anything we call) then we must push/pop them here

| .macro prologue, use_nv
| push {lr, rContext, rStack}
||if (use_nv) {
    | vpush {d8-d15}
||}
| .endmacro

| .macro epilogue, use_nv
||if (use_nv) {
    | vpop {d8-d15}
||}
| pop {lr, rContext, rStack}
| bx lr
| .endmacro

// Check if stack pos is within 1024, and use a single VLDR/VSTR with offset if so
|.define VLDR_MAX_IMM, 1024

| .macro reads, reg, stack
||if ((stack)*4 < VLDR_MAX_IMM) {
    | vldr s(reg), [rStack, #(stack)*4]
||} else {
    | add rtmp1, rStack, #(stack)*4
    | vldr s(reg), [rtmp1]
||}
| .endmacro

| .macro readv, reg, stack
| add rtmp1, rStack, #(stack)*4
| vldm rtmp1, {s(reg)-s(reg+3)}
| .endmacro

| .macro writes, stack, reg
||if ((stack)*4 < VLDR_MAX_IMM) {
    | vstr s(reg), [rStack, #(stack)*4]
||} else {
    | add rtmp1, rStack, #(stack)*4
    | vstr s(reg), [rtmp1]
||}
| .endmacro

| .macro writev, stack, reg
| add rtmp1, rStack, #(stack)*4
| vstm rtmp1, {s(reg)-s(reg+3)}
| .endmacro

| .macro writes_or_notify, reg, spos, tmpreg
||if (reg == tmpreg) {
    | writes spos, tmpreg
||} else {
    ||notifyRegisterWritten(state, reg, 1);
||}
| .endmacro

| .macro writev_or_notify, reg, spos, tmpreg
||if (reg == tmpreg) {
    | writev spos, tmpreg
||} else {
    ||notifyRegisterWritten(state, reg, 4);
||}
| .endmacro

// Define rounding modes
|.define RMODE_NEAREST, 0x00000000
|.define RMODE_POSINF,  0x00400000
|.define RMODE_NEGINF,  0x00800000
|.define RMODE_ZERO,    0x00C00000
|.define RMODE_UNKNOWN, 0xFFFFFFFF

// Set rounding mode
|.macro setrmode, mode, reg
| vmrs reg
| bic reg, reg, #0x00C00000
| orr reg, reg, #mode
| vmsr reg
||rmode = mode;
|.endmacro

|.macro ensurermode, mode, reg
||if (rmode != mode) {
    | setrmode mode, reg
||}
|.endmacro


| .macro maths1, op
||// We don't care if both reg1 and reg3 are vtmps1, it's a temp register anyway
||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1);
| op s(reg3), s(reg1)
| writes_or_notify reg3, in.arg3, vtmps1
| .endmacro

| .macro mathv1simd, op
||// We don't care if both reg1 and reg3 are vtmpv1, it's a temp register anyway
||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
||acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv1);
| op s(reg3), s(reg1)
| writev_or_notify reg3, in.arg3, vtmpv1
| .endmacro

| .macro mathv1serial, op
||// We don't care if both reg1 and reg3 are vtmpv1, it's a temp register anyway
||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
||acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv1);
| op s(reg3+0), s(reg1+0)
| op s(reg3+1), s(reg1+1)
| op s(reg3+2), s(reg1+2)
| op s(reg3+3), s(reg1+3)
| writev_or_notify reg3, in.arg3, vtmpv1
| .endmacro

| .macro maths2, op
||// We don't care if both reg1 and reg3 are vtmps1, it's a temp register anyway
||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1);
||acquireScalarRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmps2);
| op s(reg3), s(reg1), s(reg2)
| writes_or_notify reg3, in.arg3, vtmps1
| .endmacro

| .macro mathv2simd, op
||// We don't care if both reg1 and reg3 are vtmpv1, it's a temp register anyway
||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
||acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv1);
||acquireVectorRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmpv2);
| op s(reg3), s(reg1), s(reg2)
| writev_or_notify reg3, in.arg3, vtmpv1
| .endmacro

| .macro mathv2serial, op
||// We don't care if both reg1 and reg3 are vtmpv1, it's a temp register anyway
||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
||acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv1);
||acquireVectorRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmpv2);
| op s(reg3+0), s(reg1+0), s(reg2+0)
| op s(reg3+1), s(reg1+1), s(reg2+1)
| op s(reg3+2), s(reg1+2), s(reg2+2)
| op s(reg3+3), s(reg1+3), s(reg2+3)
| writev_or_notify reg3, in.arg3, vtmpv1
| .endmacro


| .macro round_with_nan_check, dst, src, jmp_if_bad
| vcvtr.s32.f32 s(dst), s(src)
|| // NaN check
| vmrs r1
| and r2, r1, #0x0F
| cmp r2, #0
| beq >1
| bic r1, r1, #0x0F
| vmsr r1
| vmov.f32 s(dst), s(src)  // propagate NaN
| b jmp_if_bad
|1:
| vcvt.f32.s32  s(dst), s(dst)
| .endmacro

| .macro rounds1, mode
||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps2);
| ensurermode mode, rtmp1
| round_with_nan_check reg3, reg1, >2
|2:
| writes_or_notify reg3, in.arg3, vtmps1
| .endmacro

| .macro roundv1, mode
||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
||acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv2);
| ensurermode mode, rtmp1
| round_with_nan_check reg3 + 0, reg1 + 0, >2
|2:
| round_with_nan_check reg3 + 1, reg1 + 1, >2
|2:
| round_with_nan_check reg3 + 2, reg1 + 2, >2
|2:
| round_with_nan_check reg3 + 3, reg1 + 3, >2
|2:
| writev_or_notify reg3, in.arg3, vtmpv1
| .endmacro


| .macro extern1, fn, offset, outarg, outreg
||if (acquireScalarRegisterOrLoad(state, in.arg1 + offset, &reg1, ACCESSTYPE_READ, 0)) {
    | vmov.f32 s0, s(reg1)
||}
||platformWriteAndEvictVolatile(state);
|.rodata
|1:
| .long (intptr_t)(&fn)
|.code
| ldr r1, <1
| blx r1
||if (acquireScalarRegister(state, outarg + offset, &outreg, ACCESSTYPE_WRITE)) {
    | vmov.f32 s(outreg), s0
    ||notifyRegisterWritten(state, outreg, 1);
||} else {
    | writes outarg, 0
||}
||rmode = RMODE_UNKNOWN;
| .endmacro

| .macro extern2, fn, offset1, offset2, offset3
||if (acquireScalarRegisterOrLoad(state, in.arg1 + offset1, &reg1, ACCESSTYPE_READ, 0)) {
    | vmov.f32 s0, s(reg1)
||}
||if (acquireScalarRegisterOrLoad(state, in.arg2 + offset2, &reg2, ACCESSTYPE_READ, 1)) {
    | vmov.f32 s1, s(reg2)
||}
||platformWriteAndEvictVolatile(state);
|.rodata
|1:
| .long (intptr_t)(&fn)
|.code
| ldr r1, <1
| blx r1
||if (acquireScalarRegister(state, in.arg3 + offset3, &reg3, ACCESSTYPE_WRITE)) {
    | vmov.f32 s(reg3), s0
    ||notifyRegisterWritten(state, reg3, 1);
||} else {
    | writes in.arg3, 0
||}
||rmode = RMODE_UNKNOWN;
| .endmacro


#include "dasm_armv7m.h"


void platformReadScalarToRegister(jit_compile_state* state, size_t reg, lmnt_offset stackpos)
{
    dasm_State** Dst = &state->dasm_state;
    | reads reg, stackpos
}

void platformWriteScalarFromRegister(jit_compile_state* state, lmnt_offset stackpos, size_t reg)
{
    dasm_State** Dst = &state->dasm_state;
    | writes stackpos, reg
}

void platformReadVectorToRegister(jit_compile_state* state, size_t reg, lmnt_offset stackpos)
{
    dasm_State** Dst = &state->dasm_state;
    | readv reg, stackpos
}

void platformWriteVectorFromRegister(jit_compile_state* state, lmnt_offset stackpos, size_t reg)
{
    dasm_State** Dst = &state->dasm_state;
    | writev stackpos, reg
}

static void platformWriteAndEvictAll(jit_compile_state* state)
{
    for (size_t i = state->fpreg->start; i < state->fpreg->end; ++i)
        writeAndEvictRegister(state, i);
}

static void platformWriteAndEvictVolatile(jit_compile_state* state)
{
    for (size_t i = LMNT_FPREG_V_START; i < LMNT_FPREG_V_END; ++i)
        writeAndEvictRegister(state, i);
}

static void platformWriteAndEvictByStack(jit_compile_state* state, lmnt_offset start, lmnt_offset end)
{
    const reg_status* s = state->fpreg->s;
    for (size_t i = state->fpreg->start; i < state->fpreg->end; ++i)
    {
        // if the first stackpos in this register is before the end of the requested block...
        // and the end of this register's last stack element is after the start of the block...
        if (s[i].stackpos < end && s[i].stackpos + s[i].count > start)
            writeAndEvictRegister(state, i);
    }
}


lmnt_result lmnt_jit_armv7m_compile(lmnt_ictx* ctx, const lmnt_def* def, lmnt_jit_fn_data* fndata, lmnt_jit_compile_stats* stats)
{
    jit_compile_state state_obj;
    jit_compile_state* const state = &state_obj;
    memset(state, 0, sizeof(jit_compile_state));

    jit_fpreg_data fpreg;
    memset(&fpreg, 0, sizeof(jit_fpreg_data));
    state->fpreg = &fpreg;

    // Work out if we're executing a locally-defined block or an extern one
    const lmnt_code* defcode;
    LMNT_OK_OR_RETURN(lmnt_archive_get_code(&ctx->archive, def->code, &defcode));
    LMNT_OK_OR_RETURN(lmnt_archive_get_code_instructions(&ctx->archive, def->code, &state->instructions));
    state->in_count = defcode->instructions_count;

    // Nothing fancy on ARMv7-M :(
    state->cpuflags = 0;

    bool use_nv = false;
    state->fpreg->start = LMNT_FPREG_V_START;
    state->fpreg->end = LMNT_FPREG_V_END;
    // TODO: decide this at runtime (based on code size?)
    #if defined(LMNT_JIT_ARM_ALLOW_NV_REGISTERS)
    // if (some_condition) {
        use_nv = true;
        state->fpreg->start = LMNT_FPREG_V_START;
        state->fpreg->end = LMNT_FPREG_NV_END;
        state->fpreg->preferred.start = LMNT_FPREG_NV_START;
        state->fpreg->preferred.end = LMNT_FPREG_NV_END;
        state->fpreg->fallback.start = LMNT_FPREG_V_START;
        state->fpreg->fallback.end = LMNT_FPREG_V_END;
    // } else {
    #else
        state->fpreg->preferred.start = LMNT_FPREG_V_START;
        state->fpreg->preferred.end = LMNT_FPREG_V_END;
    #endif
    #if defined(LMNT_JIT_ARM_ALLOW_NV_REGISTERS)
    // }
    #endif

    unsigned int num_pc_labels = 0;
    // Make PC label space for any branch instructions
    for (size_t i = 0; i < state->in_count; ++i) {
        num_pc_labels += LMNT_IS_BRANCH_OP(state->instructions[i].opcode);
    }

    lmnt_loffset branch_targets[32]; // TODO: dynamically allocate to match num_pc_labels
    unsigned int cur_branch = 0;
    for (size_t i = 0; i < state->in_count; ++i) {
        if (LMNT_IS_BRANCH_OP(state->instructions[i].opcode)) {
            branch_targets[cur_branch++] = LMNT_COMBINE_OFFSET(state->instructions[i].arg2, state->instructions[i].arg3);
        }
    }
    cur_branch = 0;

    lmnt_loffset next_target = getNextBranchTarget(branch_targets, num_pc_labels, UINT32_MAX);

    dasm_init(&state->dasm_state, DASM_MAXSECTION);
    void* labels[lbl__MAX];
    dasm_setupglobal(&state->dasm_state, labels, lbl__MAX);
    dasm_setup(&state->dasm_state, lmnt_actions);
    dasm_growpc(&state->dasm_state, num_pc_labels);

    dasm_State** Dst = &state->dasm_state;
    | .rodata
    | ->nanbits:
    | .long 0x7FC00000, 0x7FC00000, 0x7FC00000, 0x7FC00000
    | ->inftonanbits:
    | .long 0x00400000, 0x00400000, 0x00400000, 0x00400000

    | .code
    | ->lmnt_main:
    | prologue, use_nv
    | ->exec_start:

    // store LMNT stack base
    const size_t ctx_stack_offset = offsetof(lmnt_ictx, stack);
    const size_t ctx_stack_count_offset = offsetof(lmnt_ictx, cur_stack_count);
    | ldr rStack, [rArg1, #(ctx_stack_offset)]

    const lmnt_loffset icount = defcode->instructions_count;
    size_t reg1, reg2, reg3; // scratch
    size_t rmode; // VFP rounding mode
    // Set rounding mode and clear any FP exceptions
    | vmrs rtmp1
    | bic rtmp1, rtmp1, #0x00C00000
    | bic rtmp1, rtmp1, #0x1F
    | orr rtmp1, rtmp1, #(RMODE_NEGINF)
    | vmsr rtmp1
    ||rmode = RMODE_NEGINF;

    lmnt_result result = LMNT_OK;

    for (state->cur_in = 0; state->cur_in < state->in_count; ++state->cur_in)
    {
        const lmnt_instruction in = state->instructions[state->cur_in];
        // is this instruction a branch target? make a label if so
        if (state->cur_in == next_target) {
            // if we may have just jumped here, our cache status is unknown, so nuke everything
            platformWriteAndEvictAll(state);
            // find which label(s) we're meant to be
            for (size_t t = 0; t < num_pc_labels; ++t) {
                if (state->cur_in == branch_targets[t]) {
                    | =>t:
                }
            }
            next_target = getNextBranchTarget(branch_targets, num_pc_labels, next_target);
        }
        // encode instruction
        switch (in.opcode) {
        case LMNT_OP_NOOP:
            break;
        case LMNT_OP_RETURN:
            | b ->ok_return
            break;
        case LMNT_OP_ASSIGNSS:
            if (in.arg1 != in.arg3) {
                if (acquireScalarRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                    if (acquireScalarRegister(state, in.arg3, &reg3, ACCESSTYPE_WRITE)) {
                        | vmov.f32 s(reg3), s(reg1)
                        notifyRegisterWritten(state, reg3, 1);
                    } else {
                        | writes in.arg3, reg1
                    }
                } else {
                    ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
                    | reads reg3, in.arg1
                    | writes_or_notify reg3, in.arg3, vtmps1
                }
            }
            break;
        case LMNT_OP_ASSIGNVV:
            if (in.arg1 != in.arg3) {
                if (acquireVectorRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                    if (acquireVectorRegister(state, in.arg3, &reg3, ACCESSTYPE_WRITE)) {
                        if ((reg3 % 2) == 0 && (reg1 % 2) == 0) {
                            | vmov.f64 d(reg3/2 + 0), d(reg1/2 + 0)
                            | vmov.f64 d(reg3/2 + 1), d(reg1/2 + 1)
                        } else {
                            // :(
                            | vmov.f32 s(reg3 + 0), s(reg1 + 0)
                            | vmov.f32 s(reg3 + 1), s(reg1 + 1)
                            | vmov.f32 s(reg3 + 2), s(reg1 + 2)
                            | vmov.f32 s(reg3 + 3), s(reg1 + 3)
                        }
                        notifyRegisterWritten(state, reg3, 4);
                    } else {
                        | writev in.arg3, reg1
                    }
                } else {
                    ||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
                    | readv reg3, in.arg1
                    | writev_or_notify reg3, in.arg3, vtmpv1
                }
            }
            break;
        case LMNT_OP_ASSIGNSV:
            ||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
            if (acquireScalarRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3 + 0), s(reg1)
                | vmov.f32 s(reg3 + 1), s(reg1)
                if ((reg3 % 2) == 0) {
                    | vmov.f64 d(reg3/2 + 1), d(reg3/2 + 0)
                } else {
                    | vmov.f32 s(reg3 + 2), s(reg1)
                    | vmov.f32 s(reg3 + 3), s(reg1)
                }
                | writev_or_notify reg3, in.arg3, vtmpv1
            } else {
                | readv reg3, in.arg1
                | writev_or_notify reg3, in.arg3, vtmpv1
            }
            break;
        case LMNT_OP_ASSIGNIBS:
        {
            const lmnt_loffset bin = LMNT_COMBINE_OFFSET(in.arg1, in.arg2);
            | .rodata
            |1:
            | .long bin
            | .code
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | vldr s(reg3), <1
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }
        case LMNT_OP_ASSIGNIBV:
        {
            const lmnt_loffset bin = LMNT_COMBINE_OFFSET(in.arg1, in.arg2);
            | .rodata
            |1:
            | .long bin, bin, bin, bin
            | .code
            ||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
            | adr rtmp1, <1
            | vldm rtmp1, {s(reg3)-s(reg3+3)}
            | writev_or_notify reg3, in.arg3, vtmpv1
            break;
        }
        case LMNT_OP_DLOADIIS:
        {
            const lmnt_data_section* sec = validated_get_data_section(&ctx->archive, in.arg1);
            const lmnt_value* values = validated_get_data_block(&ctx->archive, sec->offset);
            const lmnt_loffset bin = *(const lmnt_loffset*)(values + in.arg2);
            | .rodata
            |1:
            | .long bin
            | .code
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | vldr s(reg3), <1
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }
        case LMNT_OP_DLOADIIV:
        {
            const lmnt_data_section* sec = validated_get_data_section(&ctx->archive, in.arg1);
            const lmnt_value* values = validated_get_data_block(&ctx->archive, sec->offset);
            const lmnt_loffset* bin = (const lmnt_loffset*)(values + in.arg2);
            | .rodata
            |1:
            | .long bin[0], bin[1], bin[2], bin[3]
            | .code
            ||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
            | adr rtmp1, <1
            | vldm rtmp1, {s(reg3)-s(reg3+3)}
            | writev_or_notify reg3, in.arg3, vtmpv1
            break;
        }
        case LMNT_OP_DLOADIRS:
        {
            const lmnt_data_section* sec = validated_get_data_section(&ctx->archive, in.arg1);
            const lmnt_value* values = validated_get_data_block(&ctx->archive, sec->offset);
            | .rodata
            |1:
            | .long values
            | .code
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps2);
            ||acquireScalarRegisterOrDefault(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmps1);
            | vcvt.s32.f32 s(reg3), s(reg2)
            | vmov rtmp2, s(reg3)
            | cmp rtmp2, #(sec->count-1)
            | bgt ->invalid_access
            | cmp rtmp2, #0
            | blt ->invalid_access
            | lsl rtmp2, rtmp2, #((int)log2f(sizeof(lmnt_value)))
            | ldr rtmp1, <1
            | add rtmp1, rtmp1, rtmp2
            | vldr s(reg3), [rtmp1]
            | writes_or_notify reg3, in.arg3, vtmps2
            break;
        }
        case LMNT_OP_DLOADIRV:
        {
            const lmnt_data_section* sec = validated_get_data_section(&ctx->archive, in.arg1);
            const lmnt_value* values = validated_get_data_block(&ctx->archive, sec->offset);
            | .rodata
            |1:
            | .long values
            | .code
            ||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv2);
            ||acquireScalarRegisterOrDefault(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmps1);
            | vcvt.s32.f32 s(reg3), s(reg2)
            | vmov rtmp2, s(reg3)
            | cmp rtmp2, #(sec->count-4)
            | bgt ->invalid_access
            | cmp rtmp2, #0
            | blt ->invalid_access
            | lsl rtmp2, rtmp2, #((int)log2f(sizeof(lmnt_value)))
            | ldr rtmp1, <1
            | add rtmp1, rtmp1, rtmp2
            | vldm rtmp1, {s(reg3)-s(reg3+3)}
            | writev_or_notify reg3, in.arg3, vtmpv2
            break;
        }
        case LMNT_OP_DSECLEN:
        {
            const lmnt_data_section* sec = validated_get_data_section(&ctx->archive, in.arg1);
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps2);
            | mov rtmp1, #(sec->count)
            | vmov s(reg3), rtmp1
            | vcvt.f32.u32 s(reg3), s(reg3)
            | writes_or_notify reg3, in.arg3, vtmps2
            break;
        }

        case LMNT_OP_ADDSS:
            | maths2 vadd.f32
            break;
        case LMNT_OP_ADDVV:
            | mathv2serial vadd.f32
            break;
        case LMNT_OP_SUBSS:
            | maths2 vsub.f32
            break;
        case LMNT_OP_SUBVV:
            | mathv2serial vsub.f32
            break;
        case LMNT_OP_MULSS:
            | maths2 vmul.f32
            break;
        case LMNT_OP_MULVV:
            | mathv2serial vmul.f32
            break;
        case LMNT_OP_DIVSS:
            | maths2 vdiv.f32
            break;
        case LMNT_OP_DIVVV:
            | mathv2serial vdiv.f32
            break;

        case LMNT_OP_REMSS:
            // call to C
            | extern2 remss, 0, 0, 0
            break;
        case LMNT_OP_REMVV:
        {
            // call to C
            | extern2 remss, 0, 0, 0
            | extern2 remss, 1, 1, 1
            | extern2 remss, 2, 2, 2
            | extern2 remss, 3, 3, 3
            break;
        }

        case LMNT_OP_SINR:
            | extern1 sinrf, 0, in.arg3, reg3
            break;
        case LMNT_OP_COSR:
            | extern1 cosrf, 0, in.arg3, reg3
            break;
        case LMNT_OP_TANR:
            | extern1 tanrf, 0, in.arg3, reg3
            break;
        case LMNT_OP_ASINR:
            | extern1 asinrf, 0, in.arg3, reg3
            break;
        case LMNT_OP_ACOSR:
            | extern1 acosrf, 0, in.arg3, reg3
            break;
        case LMNT_OP_ATANR:
            | extern1 atanrf, 0, in.arg3, reg3
            break;
        case LMNT_OP_ATAN2R:
            | extern2 atan2rf, 0, 0, 0
            break;
        case LMNT_OP_SINCOSR:
            | extern1 sinrf, 0, in.arg2, reg2
            | extern1 cosrf, 0, in.arg3, reg3
            break;

        case LMNT_OP_POWSS:
            | extern2 powf, 0, 0, 0
            break;
        case LMNT_OP_POWVV:
            | extern2 powf, 0, 0, 0
            | extern2 powf, 1, 1, 1
            | extern2 powf, 2, 2, 2
            | extern2 powf, 3, 3, 3
            break;
        case LMNT_OP_POWVS:
            | extern2 powf, 0, 0, 0
            | extern2 powf, 1, 0, 1
            | extern2 powf, 2, 0, 2
            | extern2 powf, 3, 0, 3
            break;
        case LMNT_OP_SQRTS:
            | maths1 vsqrt.f32
            break;
        case LMNT_OP_SQRTV:
            | mathv1serial vsqrt.f32
            break;
        case LMNT_OP_ABSS:
            | maths1 vabs.f32
            break;
        case LMNT_OP_ABSV:
            | mathv1serial vabs.f32
            break;
        case LMNT_OP_LN:
            | extern1 logf, 0, in.arg3, reg3
            break;
        case LMNT_OP_LOG2:
            | extern1 log2f, 0, in.arg3, reg3
            break;
        case LMNT_OP_LOG10:
            | extern1 log10f, 0, in.arg3, reg3
            break;

        case LMNT_OP_SUMV:
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            ||acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv2);
            | vmov.f32 s(reg3), s(reg1 + 0)
            | vadd.f32 s(reg3), s(reg3), s(reg1 + 1)
            | vadd.f32 s(reg3), s(reg3), s(reg1 + 2)
            | vadd.f32 s(reg3), s(reg3), s(reg1 + 3)
            | writes_or_notify reg3, in.arg3, vtmps1
            break;

        case LMNT_OP_MINSS:
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            ||if (acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1) && reg1 != reg3) {
                | vmov.f32 s(reg3), s(reg1)
            ||}
            ||acquireScalarRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmps2);
            | vcmp.f32 s(reg3), s(reg2)
            | vmrs
            | blt >1
            | vmov.f32 s(reg3), s(reg2)
            |1:
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        case LMNT_OP_MAXSS:
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            ||if (acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1) && reg1 != reg3) {
                | vmov.f32 s(reg3), s(reg1)
            ||}
            ||acquireScalarRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmps2);
            | vcmp.f32 s(reg3), s(reg2)
            | vmrs
            | bgt >1
            | vmov.f32 s(reg3), s(reg2)
            |1:
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        case LMNT_OP_MINVV:
            // :(((
            ||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
            ||if (acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv1) && reg1 != reg3) {
                | vmov.f32 s(reg3 + 0), s(reg1 + 0)
                | vmov.f32 s(reg3 + 1), s(reg1 + 1)
                | vmov.f32 s(reg3 + 2), s(reg1 + 2)
                | vmov.f32 s(reg3 + 3), s(reg1 + 3)
            ||}
            ||acquireVectorRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmpv2);
            | vcmp.f32 s(reg3 + 0), s(reg2 + 0)
            | vmrs
            | blt >1
            | vmov.f32 s(reg3 + 0), s(reg2 + 0)
            |1:
            | vcmp.f32 s(reg3 + 1), s(reg2 + 1)
            | vmrs
            | blt >2
            | vmov.f32 s(reg3 + 1), s(reg2 + 1)
            |2:
            | vcmp.f32 s(reg3 + 2), s(reg2 + 2)
            | vmrs
            | blt >3
            | vmov.f32 s(reg3 + 2), s(reg2 + 2)
            |3:
            | vcmp.f32 s(reg3 + 3), s(reg2 + 3)
            | vmrs
            | blt >4
            | vmov.f32 s(reg3 + 3), s(reg2 + 3)
            |4:
            | writev_or_notify reg3, in.arg3, vtmpv1
            break;
        case LMNT_OP_MAXVV:
            // :(((
            ||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
            ||if (acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv1) && reg1 != reg3) {
                | vmov.f32 s(reg3 + 0), s(reg1 + 0)
                | vmov.f32 s(reg3 + 1), s(reg1 + 1)
                | vmov.f32 s(reg3 + 2), s(reg1 + 2)
                | vmov.f32 s(reg3 + 3), s(reg1 + 3)
            ||}
            ||acquireVectorRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmpv2);
            | vcmp.f32 s(reg3 + 0), s(reg2 + 0)
            | vmrs
            | bgt >1
            | vmov.f32 s(reg3 + 0), s(reg2 + 0)
            |1:
            | vcmp.f32 s(reg3 + 1), s(reg2 + 1)
            | vmrs
            | bgt >2
            | vmov.f32 s(reg3 + 1), s(reg2 + 1)
            |2:
            | vcmp.f32 s(reg3 + 2), s(reg2 + 2)
            | vmrs
            | bgt >3
            | vmov.f32 s(reg3 + 2), s(reg2 + 2)
            |3:
            | vcmp.f32 s(reg3 + 3), s(reg2 + 3)
            | vmrs
            | bgt >4
            | vmov.f32 s(reg3 + 3), s(reg2 + 3)
            |4:
            | writev_or_notify reg3, in.arg3, vtmpv1
            break;
        case LMNT_OP_MINVS:
            // :(((
            ||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
            ||if (acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv1) && reg1 != reg3) {
                | vmov.f32 s(reg3 + 0), s(reg1 + 0)
                | vmov.f32 s(reg3 + 1), s(reg1 + 1)
                | vmov.f32 s(reg3 + 2), s(reg1 + 2)
                | vmov.f32 s(reg3 + 3), s(reg1 + 3)
            ||}
            ||acquireScalarRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmps2);
            | vcmp.f32 s(reg3 + 0), s(reg2)
            | vmrs
            | blt >1
            | vmov.f32 s(reg3 + 0), s(reg2)
            |1:
            | vcmp.f32 s(reg3 + 1), s(reg2)
            | vmrs
            | blt >2
            | vmov.f32 s(reg3 + 1), s(reg2)
            |2:
            | vcmp.f32 s(reg3 + 2), s(reg2)
            | vmrs
            | blt >3
            | vmov.f32 s(reg3 + 2), s(reg2)
            |3:
            | vcmp.f32 s(reg3 + 3), s(reg2)
            | vmrs
            | blt >4
            | vmov.f32 s(reg3 + 3), s(reg2)
            |4:
            | writev_or_notify reg3, in.arg3, vtmpv1
            break;
        case LMNT_OP_MAXVS:
            // :(((
            ||acquireVectorRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmpv1);
            ||if (acquireVectorRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmpv1) && reg1 != reg3) {
                | vmov.f32 s(reg3 + 0), s(reg1 + 0)
                | vmov.f32 s(reg3 + 1), s(reg1 + 1)
                | vmov.f32 s(reg3 + 2), s(reg1 + 2)
                | vmov.f32 s(reg3 + 3), s(reg1 + 3)
            ||}
            ||acquireScalarRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmps2);
            | vcmp.f32 s(reg3 + 0), s(reg2)
            | vmrs
            | bgt >1
            | vmov.f32 s(reg3 + 0), s(reg2)
            |1:
            | vcmp.f32 s(reg3 + 1), s(reg2)
            | vmrs
            | bgt >2
            | vmov.f32 s(reg3 + 1), s(reg2)
            |2:
            | vcmp.f32 s(reg3 + 2), s(reg2)
            | vmrs
            | bgt >3
            | vmov.f32 s(reg3 + 2), s(reg2)
            |3:
            | vcmp.f32 s(reg3 + 3), s(reg2)
            | vmrs
            | bgt >4
            | vmov.f32 s(reg3 + 3), s(reg2)
            |4:
            | writev_or_notify reg3, in.arg3, vtmpv1
            break;

        case LMNT_OP_FLOORS:
            | rounds1 RMODE_NEGINF
            break;
        case LMNT_OP_FLOORV:
            | roundv1 RMODE_NEGINF
            break;
        case LMNT_OP_ROUNDS:
            | rounds1 RMODE_NEAREST
            break;
        case LMNT_OP_ROUNDV:
            | roundv1 RMODE_NEAREST
            break;
        case LMNT_OP_CEILS:
            | rounds1 RMODE_POSINF
            break;
        case LMNT_OP_CEILV:
            | roundv1 RMODE_POSINF
            break;
        case LMNT_OP_TRUNCS:
            | rounds1 RMODE_ZERO
            break;
        case LMNT_OP_TRUNCV:
            | roundv1 RMODE_ZERO
            break;

        case LMNT_OP_INDEXRIS:
        {
            // Unknown at compile-time what stack addresses this is going to read from. So...
            flushAllRegisters(state);

            const uint32_t offset = (uint32_t)in.arg2;
            | .rodata
            |1:
            | .long offset
            | .code
            ||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps2);
            // Check for NaN/infinities
            | vmov rtmp1, s(reg1)
            | ldr rtmp2, ->inftonanbits
            | orr rtmp1, rtmp1, rtmp2
            | ldr rtmp2, ->nanbits
            | and rtmp1, rtmp1, rtmp2
            | cmp rtmp1, rtmp2
            | beq ->invalid_access
            // float -> int
            | vcvt.s32.f32 s(vtmps2), s(reg1)
            | vmov rtmp1, s(vtmps2)
            // index += offset
            | ldr rtmp2, <1
            | add rtmp1, rtmp1, rtmp2
            // index >= stack_count?
            | ldr rtmp2, [rArg1, #(ctx_stack_count_offset)]
            | cmp rtmp2, rtmp1
            | bls ->invalid_access
            // address = stack_address + index*sizeof(lmnt_value)
            | lsl rtmp1, rtmp1, #((int)log2f(sizeof(lmnt_value)))
            | add rtmp1, rtmp1, rStack
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | vldr s(reg3), [rtmp1]
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }
        case LMNT_OP_INDEXRIR:
        {
            // Unknown at compile-time what stack addresses this is going to read from OR WRITE TO. So...
            platformWriteAndEvictAll(state);

            const uint32_t offset = (uint32_t)in.arg2;
            | .rodata
            |1:
            | .long offset
            | .code
            ||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps2);
            // arg1: check for NaN/infinities
            | vmov rtmp1, s(reg1)
            | ldr rtmp2, ->inftonanbits
            | orr rtmp1, rtmp1, rtmp2
            | ldr rtmp2, ->nanbits
            | and rtmp1, rtmp1, rtmp2
            | cmp rtmp1, rtmp2
            | beq ->invalid_access
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_READ, vtmps1);
            // arg3: check for NaN/infinities
            | vmov rtmp1, s(reg3)
            | ldr rtmp2, ->inftonanbits
            | orr rtmp1, rtmp1, rtmp2
            | ldr rtmp2, ->nanbits
            | and rtmp1, rtmp1, rtmp2
            | cmp rtmp1, rtmp2
            | beq ->invalid_access
            // arg1: float -> int
            | vcvt.s32.f32 s(vtmps2), s(reg1)
            | vmov rtmp1, s(vtmps2)
            // arg1: index += offset
            | ldr rtmp2, <1
            | add rtmp1, rtmp1, rtmp2
            // arg1: index >= stack_count?
            | ldr rtmp2, [rArg1, #(ctx_stack_count_offset)]
            | cmp rtmp2, rtmp1
            | bls ->invalid_access
            // arg1: address = stack_address + index*sizeof(lmnt_value)
            | lsl rtmp1, rtmp1, #((int)log2f(sizeof(lmnt_value)))
            | add rtmp1, rtmp1, rStack
            | vldr s(vtmps2), [rtmp1]

            // arg3: float -> int
            | vcvt.s32.f32 s(vtmps1), s(reg3)
            | vmov rtmp1, s(vtmps1)
            // arg3: index += offset
            | ldr rtmp2, <1
            | add rtmp1, rtmp1, rtmp2
            // arg3: index >= stack_count?
            | ldr rtmp2, [rArg1, #(ctx_stack_count_offset)]
            | cmp rtmp2, rtmp1
            | bls ->invalid_access
            // arg3: address = stack_address + index*sizeof(lmnt_value)
            | lsl rtmp1, rtmp1, #((int)log2f(sizeof(lmnt_value)))
            | add rtmp1, rtmp1, rStack
            | vstr s(vtmps2), [rtmp1]

            // We could just have overwritten any of the stack we loaded into registers, so...
            // This won't write anything since we were only reading
            platformWriteAndEvictAll(state);
            break;
        }

        case LMNT_OP_CMP:
            ||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1);
            ||acquireScalarRegisterOrLoad(state, in.arg2, &reg2, ACCESSTYPE_READ, vtmps2);
            | vcmp.f32 s(reg1), s(reg2)
            | vmrs
            break;

        case LMNT_OP_CMPZ:
            ||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1);
            | vcmpz.f32 s(reg1)
            | vmrs
            break;

        case LMNT_OP_BRANCHCEQ:
            platformWriteAndEvictAll(state);
            | beq =>cur_branch
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHCNE:
            platformWriteAndEvictAll(state);
            | bne =>cur_branch
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHCLT:
            platformWriteAndEvictAll(state);
            | bcc =>cur_branch
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHCLE:
            platformWriteAndEvictAll(state);
            | bls =>cur_branch
            |1:
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHCGT:
            platformWriteAndEvictAll(state);
            | bgt =>cur_branch
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHCGE:
            platformWriteAndEvictAll(state);
            | bge =>cur_branch
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHCUN:
            platformWriteAndEvictAll(state);
            | bvs =>cur_branch
            ++cur_branch;
            break;

        case LMNT_OP_ASSIGNCEQ:
        {
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | bne >3
            if (acquireScalarRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg1)
            } else {
                | reads reg3, in.arg1
            }
            | b >4
            |3:
            if (acquireScalarRegister(state, in.arg2, &reg2, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg2)
            } else {
                | reads reg3, in.arg2
            }
            |4:
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }
        case LMNT_OP_ASSIGNCNE:
        {
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | bne >3
            if (acquireScalarRegister(state, in.arg2, &reg2, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg2)
            } else {
                | reads reg3, in.arg2
            }
            | b >4
            |3:
            if (acquireScalarRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg1)
            } else {
                | reads reg3, in.arg1
            }
            |4:
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }
        case LMNT_OP_ASSIGNCLT:
        {
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | bcc >3
            if (acquireScalarRegister(state, in.arg2, &reg2, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg2)
            } else {
                | reads reg3, in.arg2
            }
            | b >4
            |3:
            if (acquireScalarRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg1)
            } else {
                | reads reg3, in.arg1
            }
            |4:
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }
        case LMNT_OP_ASSIGNCLE:
        {
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | bls >3
            if (acquireScalarRegister(state, in.arg2, &reg2, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg2)
            } else {
                | reads reg3, in.arg2
            }
            | b >4
            |3:
            if (acquireScalarRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg1)
            } else {
                | reads reg3, in.arg1
            }
            |4:
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }
        case LMNT_OP_ASSIGNCGT:
        {
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | bgt >3
            if (acquireScalarRegister(state, in.arg2, &reg2, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg2)
            } else {
                | reads reg3, in.arg2
            }
            | b >4
            |3:
            if (acquireScalarRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg1)
            } else {
                | reads reg3, in.arg1
            }
            |4:
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }
        case LMNT_OP_ASSIGNCGE:
        {
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | bge >3
            if (acquireScalarRegister(state, in.arg2, &reg2, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg2)
            } else {
                | reads reg3, in.arg2
            }
            | b >4
            |3:
            if (acquireScalarRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg1)
            } else {
                | reads reg3, in.arg1
            }
            |4:
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }
        case LMNT_OP_ASSIGNCUN:
        {
            ||acquireScalarRegisterOrDefault(state, in.arg3, &reg3, ACCESSTYPE_WRITE, vtmps1);
            | bvs >3
            if (acquireScalarRegister(state, in.arg2, &reg2, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg2)
            } else {
                | reads reg3, in.arg2
            }
            | b >4
            |3:
            if (acquireScalarRegister(state, in.arg1, &reg1, ACCESSTYPE_READ)) {
                | vmov.f32 s(reg3), s(reg1)
            } else {
                | reads reg3, in.arg1
            }
            |4:
            | writes_or_notify reg3, in.arg3, vtmps1
            break;
        }

        case LMNT_OP_BRANCH:
            platformWriteAndEvictAll(state);
            | b =>cur_branch
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHZ:
            ||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1);
            platformWriteAndEvictAll(state);
            | vcmpz.f32 s(reg1)
            | vmrs
            | beq =>cur_branch
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHNZ:
            ||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1);
            platformWriteAndEvictAll(state);
            | vcmpz.f32 s(reg1)
            | vmrs
            | bvs >1
            | bne =>cur_branch
            |1:
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHPOS:
            ||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1);
            platformWriteAndEvictAll(state);
            | vmov rtmp1, s(reg1)
            | cmp rtmp1, #0
            | bge =>cur_branch
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHNEG:
            ||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1);
            platformWriteAndEvictAll(state);
            | vmov rtmp1, s(reg1)
            | cmp rtmp1, #0
            | blt =>cur_branch
            ++cur_branch;
            break;
        case LMNT_OP_BRANCHUN:
            ||acquireScalarRegisterOrLoad(state, in.arg1, &reg1, ACCESSTYPE_READ, vtmps1);
            platformWriteAndEvictAll(state);
            | vcmp.f32 s(reg1), s(reg1)
            | bvs =>cur_branch
            ++cur_branch;
            break;

        case LMNT_OP_EXTCALL:
        {
            lmnt_loffset def_offset = LMNT_COMBINE_OFFSET(in.arg1, in.arg2);
            const lmnt_def* def = validated_get_def(&ctx->archive, def_offset);
            const lmnt_extcall_info* extcall;
            result = lmnt_extcall_get(ctx, def->code, &extcall);
            if (result != LMNT_OK) break;
            // Make sure that anything the extcall has access to isn't cached
            platformWriteAndEvictByStack(state, in.arg3, in.arg3 + extcall->args_count + extcall->rvals_count);
            // Also evict anything volatile since the function could mess with it
            platformWriteAndEvictVolatile(state);

            |.rodata
            |1:
            | .long (const intptr_t)(extcall->function)
            |2:
            | .long (const intptr_t)(extcall)
            |.code
            | ldr r12, <1
            | mov rArg1, rContext
            | ldr rArg2, <2
            | add rArg3, rStack, #(in.arg3 * sizeof(lmnt_value))
            | add rArg4, rArg3, #(extcall->args_count * sizeof(lmnt_value))
            | blx r12
            | cmp r0, #(LMNT_OK)
            | bne ->return
            ||rmode = RMODE_UNKNOWN;
            break;
        }

        default:
            break;
        }

        if (result != LMNT_OK)
            break;

#if defined(LMNT_JIT_DEBUG_VALIDATE_REGCACHE)
        result = validateRegCache(state);
        if (result != LMNT_OK)
            break;
#endif
    }

    // has someone made a branch target to the end of the function?
    if (state->cur_in == next_target) {
        // if we may have just jumped here, our cache status is unknown, so nuke everything
        platformWriteAndEvictAll(state);
        // find which label(s) we're meant to be
        for (size_t t = 0; t < num_pc_labels; ++t) {
            if (state->cur_in == branch_targets[t]) {
                | =>t:
            }
        }
    }

    | ->ok_return:
    // Ensure our return values or any updated constants are flushed to stack
    const lmnt_offset constants_count = validated_get_constants_count(&ctx->archive);
    const lmnt_offset rvals_start = constants_count + def->args_count;
#if defined(LMNT_ALLOW_MODIFYING_STACK_CONSTANTS)
    platformWriteAndEvictByStack(state, 0, constants_count);
#endif
    platformWriteAndEvictByStack(state, rvals_start, rvals_start + def->rvals_count);
    | mov r0, #LMNT_OK
    | ->return:
    | epilogue, use_nv
    | ->invalid_access:
    // can't use a negative immediate with mov
    | mvn r0, #((-LMNT_ERROR_ACCESS_VIOLATION) - 1)
    | b ->return
    | -> lmnt_interrupt:
    | mvn r0, #((-LMNT_INTERRUPTED) - 1)
    | b -> return

    if (result == LMNT_OK) {
        fndata->def = def;
        result = targetLinkAndEncode(&state->dasm_state, &fndata->buffer, &fndata->codesize);
        if (result == LMNT_OK) {
            // + 1 to indicate the function is THUMB not ARM
            fndata->function = (lmnt_jit_fn)((uintptr_t)labels[lbl_lmnt_main] + 1);
            fndata->interrupt = (void*)((uintptr_t)labels[lbl_lmnt_interrupt] + 1);
            fndata->interruptible_start = (void*)((uintptr_t)labels[lbl_exec_start] + 1);
            fndata->interruptible_end = (void*)((uintptr_t)labels[lbl_return] + 1);
        }
    }
    dasm_free(&state->dasm_state);

#if defined(LMNT_JIT_COLLECT_STATS)
    if (stats)
        LMNT_MEMCPY(stats, &state->stats, sizeof(lmnt_jit_compile_stats));
#endif

    return result;
}
